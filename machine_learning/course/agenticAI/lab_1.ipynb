{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very simple exercise. We will openAI python package to send some messages to LLM and get responses back.\n",
    "openAI is a very thin client library in python that allows you to query some rest endpoints. These rest points trigger the various LLM's\n",
    "running in cloud. openAI python library can be used not only for chatGPT models but also other models as it is a generic API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical argument to openAI python client is a list of messages\n",
    "messages = [{\"role\": \"user\", \"content\" : \"What is 3 + 4?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_python_client = OpenAI()\n",
    "if os.getenv('OPENAI_API_KEY', None):\n",
    "    print(\"failed to find openAI API KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_python_client.chat.completions.create(\n",
    "    model = 'gpt-4.1-nano',\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now ask a high IQ question from chatGPT and let it answer by itself\n",
    "question = \"Please suggest a challenging question in mathematics that I can use to test someone's IQ. Print the question only.\"\n",
    "messages = [{\"role\": \"user\", \"content\" : question}]\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model = 'gpt-4.1-mini',\n",
    "    messages=messages\n",
    ")\n",
    "# print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)\n",
    "next_question = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\" : next_question}]\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model = 'gpt-4.1-mini',\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "answer = response.choices[0].message.content\n",
    "display(Markdown(answer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, lets ask ChatGPT to:\n",
    "# 1. Suggest a business area where agentic AI can be applied.\n",
    "# 2. Tell about a pain-point in that business area.\n",
    "# 3. Suggest an agentic AI solution to the pain-point.\n",
    "\n",
    "question = \"Please suggest a business area where agentic AI can be applied. Print the business area only.\"\n",
    "messages = [{\"role\": \"user\", \"content\" : question}]\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model = 'gpt-4.1-mini',\n",
    "    messages=messages\n",
    ")\n",
    "# print response\n",
    "business_area = response.choices[0].message.content\n",
    "print(f\"Business area: {business_area}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"Please tell me about a pain-point in {business_area}. Print the pain-point only.\"\n",
    "messages = [{\"role\": \"user\", \"content\" : question}]\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model = 'gpt-4.1-mini',\n",
    "    messages=messages\n",
    ")\n",
    "pain_point = response.choices[0].message.content\n",
    "print(f\"Pain point: {pain_point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"Please suggest an agentic AI solution to the pain-point {pain_point} in {business_area}. Print the solution only.\"\n",
    "messages = [{\"role\": \"user\", \"content\" : question}]\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model = 'gpt-4.1-mini',\n",
    "    messages=messages\n",
    ")\n",
    "solution = response.choices[0].message.content\n",
    "print(f\"Solution: {solution}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
