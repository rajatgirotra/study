{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we are going to create a tool and use it in our agentic AI solution. The tool will provide two functions.\n",
    "1. Record a message a user on your website might want to leave for you (along with user email etc)\n",
    "2. Record a question the agentic AI is not able to answer\n",
    "\n",
    "For both these functions, we will capture the information and push it directly to your phone using a pushover app.\n",
    "you need to install it on your phone and also visit pushover.net to generate API key for USER and for the APP.\n",
    "As usual this information will be stored in the .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from pypdf import PdfReader\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "pushover_user = os.getenv('PUSHOVER_USER')\n",
    "pushover_token = os.getenv('PUSHOVER_TOKEN')\n",
    "if any(x is None for x in [pushover_user, pushover_token]):\n",
    "    print(\"PUSHOVER_USER or PUSHOVER_TOKEN not found in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just test a quick pushover message.\n",
    "def push(message):\n",
    "    payload = {'user': pushover_user, 'token': pushover_token, 'message': message}\n",
    "    r = requests.post('https://api.pushover.net/1/messages.json', data=payload)\n",
    "    print(r.json())\n",
    "\n",
    "push('Hello from Pushover!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the two functions we will use in our tool.\n",
    "def record_user_details(email, name='Not provided', notes='Not provided'):\n",
    "    push(f\"recording interest from '{name}' with email '{email}'. Notes: '{notes}'\")\n",
    "    return {'recorded': 'ok'}\n",
    "\n",
    "def record_unknown_question(question):\n",
    "    push(f\"recording question: '{question}' that I could not answer\")\n",
    "    return {'recorded': 'ok'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is some boilerplate json to define the name of the tool, the description and the parameters it requires.\n",
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\", \n",
    "    \"description\": \"Use this tool to record that a user is interested in being in touch and provided an email address\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The email address of this user\"\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user's name, if they provided it\"\n",
    "            }\n",
    "            ,\n",
    "            \"notes\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any additional information about the conversation that's worth recording to give context\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Always use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question that couldn't be answered\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the list of tools that the agent can use.\n",
    "tools = [{\"type\": \"function\", \"function\": record_user_details_json},\n",
    "        {\"type\": \"function\", \"function\": record_unknown_question_json}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function can take a list of tool calls, and run them. This is the IF statement!!\n",
    "# Remember, we had said tools are nothing more than some json and some if conditions.\n",
    "\n",
    "# tool_calls is an object\n",
    "def handle_tool_calls(tool_calls):\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: {tool_name}\", flush=True)\n",
    "\n",
    "        # THE BIG IF STATEMENT!!!\n",
    "\n",
    "        if tool_name == \"record_user_details\":\n",
    "            result = record_user_details(**arguments)\n",
    "        elif tool_name == \"record_unknown_question\":\n",
    "            result = record_unknown_question(**arguments)\n",
    "\n",
    "        # this is the result which will be returned to the agent. Note the \"role\" is \"tool\", not \"user\" or \"system\"\n",
    "        # also we return a list of results.\n",
    "        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pythonic way of converting the string to a function with the same name.\n",
    "# globals is a dictionary of all the global variables in the current scope.\n",
    "globals()[\"record_unknown_question\"](\"this is a really hard question\") # this will push a message to your phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool_calls is an object\n",
    "def handle_tool_calls(tool_calls):\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: {tool_name}\", flush=True)\n",
    "        tool = globals().get(tool_name)\n",
    "        result = tool(**arguments) if tool else {}\n",
    "        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now prepare to read the linkedin.pdf and the summary.txt file as in the previous lab.\n",
    "name = 'Rajat Girotra'\n",
    "summary = ''\n",
    "with open('summary.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "linkedin = ''\n",
    "reader = PdfReader('linkedin.pdf')\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    linkedin += text\n",
    "\n",
    "print(summary)\n",
    "print(linkedin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer to any question, use your record_unknown_question tool to record the question that you couldn't answer, even if it's about something trivial or unrelated to career. \\\n",
    "If the user is engaging in discussion, try to steer them towards getting in touch via email; ask for their email and record it using your record_user_details tool. \"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_python_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the most important function\n",
    "# here we will parse the user message and see if we need a tool call and how to make it and get results back.\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    done = False\n",
    "    while not done:\n",
    "        # send message to agent\n",
    "        response = openai_python_client.chat.completions.create(model='gpt-4o-mini', messages=messages, tools=tools)\n",
    "\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        print(f\"finish_reason: {finish_reason}\")\n",
    "\n",
    "        # finish_reason is used to check if LLM wants a tool call.\n",
    "        if finish_reason == 'tool_calls':\n",
    "            # we dont get the content from the message object. infact we get the tool_calls object\n",
    "            msg = response.choices[0].message\n",
    "            tool_calls = msg.tool_calls\n",
    "            print(f\"type(tool_calls): {type(tool_calls)}\")\n",
    "            results = handle_tool_calls(tool_calls)\n",
    "            # why we do this? We are creating a new prompt for the LLM with the result of the tools call.\n",
    "            # if the tool call is successful, the LLM will see that and in the second iteration, the finish_reason will not be 'tool_calls'\n",
    "            # it will just be 'stop'\n",
    "            messages.append(msg) \n",
    "            messages.extend(results) \n",
    "            print(f\"extended messages: {messages}\")\n",
    "        else:\n",
    "            done = True\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# A sample message i.e. ChatCompletionMessage which has many attributes using tool_calls which is a list of ChatCompletionMessageToolCall, ie list of tool calls we need to make.\n",
    "# that is why we loop through the tool_calls and call the handle_tool_calls function to make all the tool calls. and in the result we append the tool call id.\n",
    "# msg = ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8G9yjI0aiKljPzFXJGvStOAu', function=Function(arguments='{\"question\":\"who are you?\"}', name='record_unknown_question'), type='function')]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
